{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7777ac1",
   "metadata": {},
   "source": [
    "# Task 02: Exploratory Data Analysis (Part 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c1696",
   "metadata": {},
   "source": [
    "## Identifying \"Noise\" and Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe8973",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae41d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "from collections import Counter \n",
    "\n",
    "train_path = Path(\"../data/processed/pcl_task1_train.csv\")\n",
    "dev_path = Path(\"../data/processed/pcl_task1_dev.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df = pd.read_csv(dev_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14783eab",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3b0230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "duplicate texts: 0\n",
      "duplicate par_ids: 0\n",
      "\n",
      "DEV\n",
      "duplicate texts: 0\n",
      "duplicate par_ids: 0\n",
      "\n",
      "train/dev text overlap: 0\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates(df, name):\n",
    "    print(name)\n",
    "    print(\"duplicate texts:\", df[\"text\"].duplicated().sum())\n",
    "    print(\"duplicate par_ids:\", df[\"par_id\"].duplicated().sum())\n",
    "    print()\n",
    "\n",
    "check_duplicates(train_df, \"TRAIN\")\n",
    "check_duplicates(dev_df, \"DEV\")\n",
    "\n",
    "# leakage\n",
    "overlap = set(train_df.text) & set(dev_df.text)\n",
    "print(\"train/dev text overlap:\", len(overlap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02890002",
   "metadata": {},
   "source": [
    "### Split leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d46befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/dev text overlap: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = set(train_df[\"text\"])\n",
    "dev_texts = set(dev_df[\"text\"])\n",
    "\n",
    "overlap = train_texts & dev_texts\n",
    "print(\"train/dev text overlap:\", len(overlap))\n",
    "\n",
    "# optional inspect\n",
    "list(overlap)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b75b632",
   "metadata": {},
   "source": [
    "### Special characters/HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1731215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact count: 91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['People who are homeless , those who were once homeless , those working with the homeless and concerned New Zealanders are being asked to share their experiences and solutions to this growing issue with the Cross-Party Homelessness Inquiry . More&gt;&gt;',\n",
       " \"The departures from London will barely put a dent in S&amp;P 's overall presence in Europe 's main financial centre . But Peterson warned Britain needed to provide clarity on key post-Brexit regulatory arrangements to ensure there is n't more upheaval .\",\n",
       " \"Another collective sale leads the region 's real estate headlines again today as Asia gets back to work after the western holiday season , with the owners of a housing development hoping to bring in S$355 million to be homeless . Meanwhile , Guangzhou R&amp;F is the latest mainland giant to report encouraging sales numbers and there 's much more if you just read on .\",\n",
       " 'Bank of America \\'s biggest competitors do n\\'t have specific policies on employment for DACA permit holders , but Goldman Sachs Group Inc. and JP Morgan Chase &amp; Co. said they support a legal path to citizenship . Wells Fargo &amp; Co. , which has been sued for allegedly discriminating against Dreamers applying for loans , said in a statement that \" the protection of DACA immigrants is relevant to our team members and the communities we serve . \"',\n",
       " '\" As Briggs &amp; Stratton celebrates its 110th anniversary year , what better way to reaffirm our commitment to the Milwaukee community than by providing $1 million to kids in need of pediatric care , \" said Rick Carpenter , vice president corporate marketing . \" We are lucky to have one of the nation \\'s top pediatric hospitals right here within our community and Briggs &amp; Stratton firmly stands behind its commitment to extend its support into the future . \"']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_patterns = [\n",
    "    r\"&\\w+;\",     # &amp; &quot;\n",
    "    r\"\\\\n\",       # escaped newline\n",
    "    r\"\\s{3,}\",    # huge spacing\n",
    "    r\"http\\S+\",   # URLs\n",
    "    r\"\\w+\\.\\w+\\.\\w+\", # domains\n",
    "]\n",
    "\n",
    "def find_artifacts(texts, n=20):\n",
    "    hits = []\n",
    "    for t in texts:\n",
    "        for p in artifact_patterns:\n",
    "            if re.search(p, t):\n",
    "                hits.append(t)\n",
    "                break\n",
    "    return hits[:n], len(hits)\n",
    "\n",
    "examples, total = find_artifacts(train_df[\"text\"])\n",
    "print(\"artifact count:\", total)\n",
    "examples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb470b4",
   "metadata": {},
   "source": [
    "- will need to normalise during data cleanup so strip these before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1fcc2",
   "metadata": {},
   "source": [
    "### Outliers (length profiling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47e794",
   "metadata": {},
   "source": [
    "- Most of length profiling and visualisations done in basic stat profiling (EDA_stat_profiling.ipyng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b3ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    8375.000000\n",
      "mean       48.675224\n",
      "std        29.677952\n",
      "min         1.000000\n",
      "1%          8.000000\n",
      "5%         16.000000\n",
      "50%        42.000000\n",
      "95%       102.000000\n",
      "99%       142.000000\n",
      "max       909.000000\n",
      "Name: tok_len, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok_len</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>909</td>\n",
       "      <td>Dr Mayengbam Lalit Singh Recently honourable P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>512</td>\n",
       "      <td>Most are from desperately poor Horn of Africa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>419</td>\n",
       "      <td>Mahinda Wijesinghe , the Inspector General of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>390</td>\n",
       "      <td>ANNUAL State of Education Report ( ASER ) laun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>266</td>\n",
       "      <td>The following is a brief history of the Rajnee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tok_len                                               text\n",
       "7267      909  Dr Mayengbam Lalit Singh Recently honourable P...\n",
       "6695      512  Most are from desperately poor Horn of Africa ...\n",
       "5862      419  Mahinda Wijesinghe , the Inspector General of ...\n",
       "8031      390  ANNUAL State of Education Report ( ASER ) laun...\n",
       "285       266  The following is a brief history of the Rajnee..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"char_len\"] = train_df[\"text\"].str.len()\n",
    "train_df[\"tok_len\"] = train_df[\"text\"].str.split().str.len()\n",
    "\n",
    "print(train_df[\"tok_len\"].describe(percentiles=[.01,.05,.95,.99]))\n",
    "\n",
    "# inspect extreme short\n",
    "train_df.nsmallest(5, \"tok_len\")[[\"tok_len\",\"text\"]]\n",
    "\n",
    "# inspect extreme long\n",
    "train_df.nlargest(5, \"tok_len\")[[\"tok_len\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc09e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
